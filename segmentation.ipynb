{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.contrib.framework.python.ops import variables\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from input import *\n",
    "from model import *\n",
    "from train import *\n",
    "import matplotlib.pyplot as plt\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.contrib.data.python.ops.dataset_ops.Iterator object at 0x11713d828> Tensor(\"training_data/input:0\", shape=(?,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "image_shape = (160,576)\n",
    "iterator, filename = get_train_inputs(batch_size=100,\n",
    "                                      repeat=True, \n",
    "                                      num_classes=2, \n",
    "                                      image_shape=image_shape)\n",
    "print(iterator, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_show = False\n",
    "if _show:\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(iterator.initializer, feed_dict={filename: ['data/kitti_segmentation.tfrecord']})\n",
    "        next_element = iterator.get_next()\n",
    "        i = 1\n",
    "        while i < 5:\n",
    "            i += 1\n",
    "            print(\"*\"*10)\n",
    "            image, label = sess.run(next_element)\n",
    "            new = scipy.misc.imresize(image,(160*2,576*2) )\n",
    "            plt.imshow(image[:,:,:])\n",
    "            plt.show()\n",
    "            plt.imshow(new[:,:,:])\n",
    "#             plt.imshow(label[:,:,0], cmap='jet', alpha=0.5)\n",
    "            plt.show()\n",
    "            print(new.shape, image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# record_iterator = tf.python_io.tf_record_iterator(path='data/kitti_segmentation.tfrecord')\n",
    "# string_record = next(record_iterator)\n",
    "# example = tf.train.Example()\n",
    "# example.ParseFromString(string_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = SlimModelEncoder(name=\"vgg_16\", num_classes=2, is_training=True)\n",
    "image, label = iterator.get_next()\n",
    "assign_op, feed_dict, end_points = encoder.build(image=image, image_shape=image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_points.keys()\n",
    "gr = tf.get_default_graph()\n",
    "gr.get_collection('table_initializer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"vgg_16/conv3/conv3_3/Relu:0\", shape=(1, 40, 144, 256), dtype=float32)\n",
      "Tensor(\"vgg_16/conv4/conv4_3/Relu:0\", shape=(1, 20, 72, 512), dtype=float32)\n",
      "Tensor(\"vgg_16/conv5/conv5_3/Relu:0\", shape=(1, 10, 36, 512), dtype=float32)\n",
      "Tensor(\"vgg_16/fc6/Relu:0\", shape=(1, 5, 18, 4096), dtype=float32)\n",
      "Tensor(\"vgg_16/fc7/Relu:0\", shape=(1, 5, 18, 4096), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(end_points['vgg_16/conv3/conv3_3'], \n",
    "    end_points['vgg_16/conv4/conv4_3'], \n",
    "    end_points['vgg_16/conv5/conv5_3'],\n",
    "    end_points['vgg_16/fc6'],\n",
    "    end_points['vgg_16/fc7'],sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder = FCNDecoder(end_points, nb_classes=2, scope='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensors_to_connect = OrderedDict()\n",
    "tensors_to_connect[\"vgg_16/fc7\"] = (2,2)\n",
    "tensors_to_connect['vgg_16/conv5/conv5_3'] = (2,2)\n",
    "tensors_to_connect['vgg_16/conv4/conv4_3'] = (8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = decoder.build(tensors_to_connect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert tuple(gr.get_tensor_by_name('logit:0').get_shape().as_list()[1:3]) == image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(nb_classes=2, optimizer=tf.train.AdamOptimizer, learning_rate=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred shape (92160, 2), label shape (92160, 2)\n"
     ]
    }
   ],
   "source": [
    "trainer.build(predictions=net, labels=label, decoder_scope='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path /tmp/tf/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:global step 1: loss = 0.6938 (6.307 sec/step)\n",
      "INFO:tensorflow:global step 2: loss = 0.6926 (2.749 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2.\n",
      "INFO:tensorflow:global step 3: loss = 0.6918 (3.084 sec/step)\n",
      "INFO:tensorflow:global step 4: loss = 0.6911 (2.128 sec/step)\n",
      "INFO:tensorflow:global step 5: loss = 0.6906 (2.101 sec/step)\n",
      "INFO:tensorflow:global step 6: loss = 0.6892 (2.031 sec/step)\n",
      "INFO:tensorflow:global step 7: loss = 0.6889 (2.238 sec/step)\n",
      "INFO:tensorflow:global step 8: loss = 0.6874 (2.583 sec/step)\n",
      "INFO:tensorflow:global step 9: loss = 0.6863 (2.356 sec/step)\n",
      "INFO:tensorflow:global step 10: loss = 0.6871 (2.670 sec/step)\n",
      "INFO:tensorflow:global step 11: loss = 0.6851 (2.663 sec/step)\n",
      "INFO:tensorflow:global step 12: loss = 0.6856 (2.176 sec/step)\n",
      "INFO:tensorflow:global step 13: loss = 0.6835 (2.062 sec/step)\n",
      "INFO:tensorflow:global step 14: loss = 0.6828 (2.052 sec/step)\n",
      "INFO:tensorflow:global step 15: loss = 0.6819 (2.048 sec/step)\n",
      "INFO:tensorflow:global step 16: loss = 0.6805 (2.044 sec/step)\n",
      "INFO:tensorflow:global step 17: loss = 0.6801 (2.032 sec/step)\n",
      "INFO:tensorflow:global step 18: loss = 0.6775 (2.058 sec/step)\n",
      "INFO:tensorflow:global step 19: loss = 0.6740 (2.065 sec/step)\n",
      "INFO:tensorflow:global step 20: loss = 0.6759 (2.042 sec/step)\n",
      "INFO:tensorflow:global step 21: loss = 0.6762 (2.048 sec/step)\n",
      "INFO:tensorflow:global step 22: loss = 0.6754 (2.022 sec/step)\n",
      "INFO:tensorflow:global step 23: loss = 0.6752 (2.051 sec/step)\n",
      "INFO:tensorflow:global step 24: loss = 0.6748 (2.045 sec/step)\n",
      "INFO:tensorflow:global step 25: loss = 0.6745 (2.085 sec/step)\n",
      "INFO:tensorflow:global step 26: loss = 0.6740 (2.059 sec/step)\n",
      "INFO:tensorflow:global step 27: loss = 0.6721 (2.046 sec/step)\n",
      "INFO:tensorflow:global step 28: loss = 0.6707 (2.049 sec/step)\n",
      "INFO:tensorflow:global step 29: loss = 0.6688 (2.044 sec/step)\n"
     ]
    }
   ],
   "source": [
    "trainer.train(iterator, assign_op=assign_op, feed_dict=feed_dict, filename=['data/kitti_segmentation.tfrecord'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"/tmp/tf\"\n",
    "with tf.Graph().as_default() as graph:\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.import_meta_graph(os.path.join(TRAIN_DIR,\"model.ckpt-1000.meta\"))\n",
    "        saver.restore(sess, os.path.join(TRAIN_DIR,\"model.ckpt-1000\"))\n",
    "        # predictions and labels\n",
    "        logit = graph.get_tensor_by_name('decoder/Conv2d_transpose_2/Relu:0')\n",
    "        input_tensor = graph.get_tensor_by_name('training_data/input:0')   \n",
    "        print(input_tensor)\n",
    "        # (1, 160, 576, 2) -> (160, 576, 2)\n",
    "        logit = tf.squeeze(logit)\n",
    "        pred = tf.argmax(logit, axis=2)\n",
    "        #sess.run(iterator.initializer, feed_dict={input_tensor: filename})\n",
    "        pred = sess.run(pred)\n",
    "        #print(pred, pred.shape())     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gr = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gr.collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
