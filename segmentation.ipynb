{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.contrib.framework.python.ops import variables\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from input import *\n",
    "from model import *\n",
    "from train import *\n",
    "import matplotlib.pyplot as plt\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_shape = (160,576)\n",
    "iterator, filename = get_train_inputs(batch_size=100,\n",
    "                                      repeat=True, \n",
    "                                      num_classes=2, \n",
    "                                      image_shape=image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_show = False\n",
    "if _show:\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(iterator.initializer, feed_dict={filename: ['data/kitti_segmentation.tfrecord']})\n",
    "        next_element = iterator.get_next()\n",
    "        i = 1\n",
    "        while i < 10:\n",
    "            i += 1\n",
    "            print(\"*\"*10)\n",
    "            image, label = sess.run(next_element)\n",
    "            print(image.shape, label.shape)\n",
    "            plt.imshow(np.uint8(image))\n",
    "            plt.imshow(label[:,:,0], cmap='jet', alpha=0.5)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# record_iterator = tf.python_io.tf_record_iterator(path='data/kitti_segmentation.tfrecord')\n",
    "# string_record = next(record_iterator)\n",
    "# example = tf.train.Example()\n",
    "# example.ParseFromString(string_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restore following variables: [<tf.Variable 'vgg_16/conv1/conv1_1/weights:0' shape=(3, 3, 3, 64) dtype=float32_ref>, <tf.Variable 'vgg_16/conv1/conv1_1/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv1/conv1_2/weights:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'vgg_16/conv1/conv1_2/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv2/conv2_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'vgg_16/conv2/conv2_1/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv2/conv2_2/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'vgg_16/conv2/conv2_2/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_1/weights:0' shape=(3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_1/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_2/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_3/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'vgg_16/conv3/conv3_3/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_1/weights:0' shape=(3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_1/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_2/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_2/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_3/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv4/conv4_3/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_1/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_1/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_2/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_2/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_3/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'vgg_16/conv5/conv5_3/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'vgg_16/fc6/weights:0' shape=(7, 7, 512, 4096) dtype=float32_ref>, <tf.Variable 'vgg_16/fc6/biases:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'vgg_16/fc7/weights:0' shape=(1, 1, 4096, 4096) dtype=float32_ref>, <tf.Variable 'vgg_16/fc7/biases:0' shape=(4096,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "encoder = SlimModelEncoder(name=\"vgg_16\", num_classes=2, is_training=True)\n",
    "image, label = iterator.get_next()\n",
    "restore_fn, end_points = encoder.build(image=image, image_shape=image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:1\", shape=(160, 576, 2), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['vgg_16/conv1/conv1_1', 'vgg_16/conv1/conv1_2', 'vgg_16/pool1', 'vgg_16/conv2/conv2_1', 'vgg_16/conv2/conv2_2', 'vgg_16/pool2', 'vgg_16/conv3/conv3_1', 'vgg_16/conv3/conv3_2', 'vgg_16/conv3/conv3_3', 'vgg_16/pool3', 'vgg_16/conv4/conv4_1', 'vgg_16/conv4/conv4_2', 'vgg_16/conv4/conv4_3', 'vgg_16/pool4', 'vgg_16/conv5/conv5_1', 'vgg_16/conv5/conv5_2', 'vgg_16/conv5/conv5_3', 'vgg_16/pool5', 'vgg_16/fc6', 'vgg_16/fc7', 'vgg_16/fc8'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_points.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'vgg_16/conv1/conv1_1/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/conv1/conv1_2/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/conv2/conv2_1/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/conv2/conv2_2/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/conv3/conv3_1/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/conv3/conv3_2/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/conv3/conv3_3/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/conv4/conv4_1/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/conv4/conv4_2/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/conv4/conv4_3/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/conv5/conv5_1/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/conv5/conv5_2/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/conv5/conv5_3/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/fc6/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/fc7/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'vgg_16/fc8/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(ops.GraphKeys.REGULARIZATION_LOSSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"vgg_16/pool3/MaxPool:0\", shape=(1, 20, 72, 256), dtype=float32)\n",
      "Tensor(\"vgg_16/pool4/MaxPool:0\", shape=(1, 10, 36, 512), dtype=float32)\n",
      "Tensor(\"vgg_16/conv5/conv5_3/Relu:0\", shape=(1, 10, 36, 512), dtype=float32)\n",
      "Tensor(\"vgg_16/fc7/Relu:0\", shape=(1, 5, 18, 4096), dtype=float32)\n",
      "Tensor(\"vgg_16/fc8/BiasAdd:0\", shape=(1, 5, 18, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(end_points['vgg_16/pool3'], \n",
    "    end_points['vgg_16/pool4'], \n",
    "    end_points['vgg_16/conv5/conv5_3'],\n",
    "    end_points['vgg_16/fc7'],\n",
    "    end_points['vgg_16/fc8'],sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder = FCNDecoder(end_points, nb_classes=2, scope='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tensors_to_connect = OrderedDict()\n",
    "tensors_to_connect[\"vgg_16/fc8\"] = (2,2)\n",
    "tensors_to_connect['vgg_16/pool4'] = (2,2)\n",
    "tensors_to_connect['vgg_16/pool3'] = (8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = decoder.build(tensors_to_connect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert tuple(net.get_shape().as_list()[1:3]) == image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'vgg_16/conv1/conv1_1/weights:0' shape=(3, 3, 3, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv1/conv1_1/biases:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv1/conv1_2/weights:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv1/conv1_2/biases:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv2/conv2_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv2/conv2_1/biases:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv2/conv2_2/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv2/conv2_2/biases:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv3/conv3_1/weights:0' shape=(3, 3, 128, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv3/conv3_1/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv3/conv3_2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv3/conv3_2/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv3/conv3_3/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv3/conv3_3/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv4/conv4_1/weights:0' shape=(3, 3, 256, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv4/conv4_1/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv4/conv4_2/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv4/conv4_2/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv4/conv4_3/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv4/conv4_3/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv5/conv5_1/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv5/conv5_1/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv5/conv5_2/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv5/conv5_2/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv5/conv5_3/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/conv5/conv5_3/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/fc6/weights:0' shape=(7, 7, 512, 4096) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/fc6/biases:0' shape=(4096,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/fc7/weights:0' shape=(1, 1, 4096, 4096) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/fc7/biases:0' shape=(4096,) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/fc8/weights:0' shape=(1, 1, 4096, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'vgg_16/fc8/biases:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/Conv/weights:0' shape=(1, 1, 2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/Conv/biases:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/upsample_conv_0/weights:0' shape=(4, 4, 2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/upsample_conv_0/biases:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/Conv_1/weights:0' shape=(1, 1, 512, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/Conv_1/biases:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/upsample_conv_1/weights:0' shape=(4, 4, 2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/upsample_conv_1/biases:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/Conv_2/weights:0' shape=(1, 1, 256, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/Conv_2/biases:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/upsample_conv_2/weights:0' shape=(16, 16, 2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/upsample_conv_2/biases:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection('trainable_variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'decoder/Conv/BiasAdd:0' shape=(1, 5, 18, 2) dtype=float32>,\n",
       " <tf.Tensor 'decoder/upsample_conv_0/BiasAdd:0' shape=(1, 10, 36, 2) dtype=float32>,\n",
       " <tf.Tensor 'decoder/Conv_1/BiasAdd:0' shape=(1, 10, 36, 2) dtype=float32>,\n",
       " <tf.Tensor 'decoder/upsample_conv_1/BiasAdd:0' shape=(1, 20, 72, 2) dtype=float32>,\n",
       " <tf.Tensor 'decoder/Conv_2/BiasAdd:0' shape=(1, 20, 72, 2) dtype=float32>,\n",
       " <tf.Tensor 'decoder/upsample_conv_2/BiasAdd:0' shape=(1, 160, 576, 2) dtype=float32>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection('decoder_end_points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(nb_classes=2, optimizer=tf.train.AdamOptimizer, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'decoder/upsample_conv_2/BiasAdd:0' shape=(1, 160, 576, 2) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred shape (92160, 2), label shape (92160, 2)\n"
     ]
    }
   ],
   "source": [
    "trainer.build(predictions=net, labels=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_checkpoints/vgg_16.ckpt\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path /tmp/tf/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Recording summary at step 0.\n",
      "INFO:tensorflow:global step 1: loss = 1.9657 (15.927 sec/step)\n",
      "INFO:tensorflow:global step 2: loss = 1.7266 (8.195 sec/step)\n",
      "INFO:tensorflow:global step 3: loss = 1.6171 (7.499 sec/step)\n",
      "INFO:tensorflow:global step 4: loss = 1.5311 (7.877 sec/step)\n",
      "INFO:tensorflow:global step 5: loss = 1.4173 (7.750 sec/step)\n",
      "INFO:tensorflow:global step 6: loss = 1.4101 (7.558 sec/step)\n",
      "INFO:tensorflow:global step 7: loss = 1.3737 (8.766 sec/step)\n",
      "INFO:tensorflow:global step 8: loss = 1.3341 (7.441 sec/step)\n",
      "INFO:tensorflow:global step 9: loss = 1.2972 (8.466 sec/step)\n",
      "INFO:tensorflow:global step 10: loss = 1.2471 (7.676 sec/step)\n",
      "INFO:tensorflow:global step 11: loss = 1.2205 (10.747 sec/step)\n",
      "INFO:tensorflow:global step 12: loss = 1.2003 (9.706 sec/step)\n",
      "INFO:tensorflow:global step 13: loss = 1.1831 (7.918 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 0.108315\n",
      "INFO:tensorflow:global step 14: loss = 1.1637 (12.892 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 14.\n",
      "INFO:tensorflow:global step 15: loss = 1.1400 (11.802 sec/step)\n",
      "INFO:tensorflow:global step 16: loss = 1.1254 (8.510 sec/step)\n",
      "INFO:tensorflow:global step 17: loss = 1.1149 (11.748 sec/step)\n",
      "INFO:tensorflow:global step 18: loss = 1.0998 (9.922 sec/step)\n",
      "INFO:tensorflow:global step 19: loss = 1.0838 (10.024 sec/step)\n",
      "INFO:tensorflow:global step 20: loss = 1.0713 (9.033 sec/step)\n",
      "INFO:tensorflow:global step 21: loss = 1.0609 (8.803 sec/step)\n",
      "INFO:tensorflow:global step 22: loss = 1.0473 (8.251 sec/step)\n"
     ]
    }
   ],
   "source": [
    "trainer.train(iterator, \n",
    "              restore_fn=restore_fn, \n",
    "              number_of_steps=2500, \n",
    "              filename=['data/kitti_segmentation.tfrecord'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"model_checkpoints/\"\n",
    "with tf.Graph().as_default() as graph:\n",
    "    image_shape = (160,576)\n",
    "    iterator, filename = get_train_inputs(batch_size=1,\n",
    "                                      repeat=False, \n",
    "                                      num_classes=2, \n",
    "                                      image_shape=image_shape)\n",
    "    encoder = SlimModelEncoder(name=\"vgg_16\", num_classes=2, is_training=False)\n",
    "    image, label = iterator.get_next()\n",
    "    assign_op, end_points = encoder.build(image=image, image_shape=image_shape)\n",
    "    # tensors to connect and encoder\n",
    "    decoder = FCNDecoder(end_points, nb_classes=2, scope='decoder')\n",
    "    tensors_to_connect = OrderedDict()\n",
    "    tensors_to_connect[\"vgg_16/fc8\"] = (2,2)\n",
    "    tensors_to_connect['vgg_16/pool4'] = (2,2)\n",
    "    tensors_to_connect['vgg_16/pool3'] = (8,8)\n",
    "    net = decoder.build(tensors_to_connect)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, os.path.join(TRAIN_DIR,\"model.ckpt-2500\"))\n",
    "        input_tensor = graph.get_tensor_by_name('training_data/input:0')\n",
    "        sess.run(iterator.initializer, feed_dict={input_tensor: ['data/kitti_segmentation.tfrecord']})\n",
    "        i = 0\n",
    "        while i < 10:\n",
    "            i += 1\n",
    "            # inference\n",
    "            print(net)\n",
    "            net = tf.squeeze(net)\n",
    "            out = sess.run(net)\n",
    "            img = sess.run(image)\n",
    "            plt.imshow(np.uint8(img))\n",
    "            _argmax = np.argmax(out,axis=2)\n",
    "            plt.imshow(_argmax, cmap='jet', alpha=0.5)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_argmax = np.argmax(label,axis=2)\n",
    "plt.imshow(_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_argmax = np.argmax(out,axis=2)\n",
    "plt.imshow(_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
